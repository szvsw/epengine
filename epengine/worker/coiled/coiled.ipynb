{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import coiled\n",
    "from archetypal.idfclass import IDF\n",
    "from archetypal.idfclass.sql import Sql\n",
    "from pydantic import AnyUrl\n",
    "\n",
    "from epengine.models.configs import SimulationSpec\n",
    "from epengine.utils.results import postprocess, serialize_df_dict\n",
    "\n",
    "AWS_ACCOUNT_ID = os.environ[\"AWS_ACCOUNT_ID\"]\n",
    "AWS_REGION = os.environ[\"AWS_REGION\"]\n",
    "HATCHET_CLIENT_TOKEN = os.environ[\"HATCHET_CLIENT_TOKEN\"]\n",
    "AWS_BUCKET = \"ml-for-bem\"\n",
    "\n",
    "worker_image_name = \"ml-for-bem-coiledworker\"\n",
    "worker_image_name = \"hatchet/epengine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly Matched Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@coiled.function(\n",
    "    region=\"us-east-1\",\n",
    "    vm_type=[\"t3.medium\", \"t3.large\"],\n",
    "    container=f\"{AWS_ACCOUNT_ID}.dkr.ecr.{AWS_REGION}.amazonaws.com/{worker_image_name}:latest\",\n",
    ")\n",
    "def run_simulation(data: dict[str, str], ix: int):\n",
    "    \"\"\"Run a simulation using the provided data and return the results.\n",
    "\n",
    "    Args:\n",
    "        data (dict[str, str]): The data to run the simulation with.\n",
    "        ix (int): The index of the simulation.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, pd.DataFrame]: The results of the simulation\n",
    "    \"\"\"\n",
    "    spec = SimulationSpec.model_validate(data)\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        idf = IDF(\n",
    "            spec.idf_path,  # pyright: ignore [reportArgumentType]\n",
    "            epw=spec.epw_path,\n",
    "            output_directory=tmpdir,\n",
    "        )  # pyright: ignore [reportArgumentType]\n",
    "        idf.simulate()\n",
    "        sql = Sql(idf.sql_file)\n",
    "        index_data = spec.model_dump(mode=\"json\", exclude_none=True)\n",
    "        index_data[\"spawn_index\"] = ix\n",
    "        # TODO: pull in spawn index\n",
    "        dfs = postprocess(\n",
    "            sql,\n",
    "            index_data=index_data,\n",
    "            tabular_lookups=[(\"AnnualBuildingUtilityPerformanceSummary\", \"End Uses\")],\n",
    "        )\n",
    "    dfs = serialize_df_dict(dfs)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = SimulationSpec(\n",
    "    experiment_id=\"coiled-test\",\n",
    "    idf_uri=AnyUrl(f\"s3://{AWS_BUCKET}/hatchet/insomnia-test/idf/Office_totalBaseline.idf\"),\n",
    "    epw_uri=AnyUrl(f\"s3://{AWS_BUCKET}/hatchet/insomnia-test/epw/ARG_Buenos.Aires.875760_IWEC.epw\"),\n",
    "    ddy_uri=None,\n",
    ")\n",
    "arg = spec.model_dump(mode=\"json\")\n",
    "results = run_simulation.map([arg for _ in range(10)], range(10), errors=\"skip\")\n",
    "results = list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client submitted function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"../../../data/taube-spec-small-20.json\") as f:\n",
    "    data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "df[\"epw_uri\"] = df.epw_path.apply(lambda x: f\"s3://ml-for-bem/hatchet/taube-archetypal-updated-bsmt/epw/{x}\")\n",
    "df[\"idf_uri\"] = df.idf_path.apply(lambda x: f\"s3://ml-for-bem/hatchet/taube-archetypal-updated-bsmt/idf/{x}\")\n",
    "df[\"ddy_uri\"] = df.ddy_path.apply(lambda x: f\"s3://ml-for-bem/hatchet/taube-archetypal-updated-bsmt/ddy/{x}\")\n",
    "df = df.drop(columns=[\"epw_path\", \"idf_path\", \"ddy_path\"])\n",
    "df[\"sort_ix\"] = df.index.copy(deep=True)\n",
    "sim_specs = [SimulationSpec(**x, experiment_id=\"coiled-test-0\") for x in df.to_dict(orient=\"records\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-22 17:38:11,358][INFO    ][coiled] Creating software environment\n",
      "[2024-09-22 17:38:11,464][INFO    ][coiled] Software environment created\n",
      "[2024-09-22 17:38:12,134][INFO    ][coiled] Creating Cluster (name: hatchet-worker-cluster, https://cloud.coiled.io/clusters/597308?account=szvsw ). This usually takes 1-2 minutes...\n",
      "c:\\Users\\szvsw\\repos\\epengine\\.venv\\lib\\site-packages\\distributed\\client.py:1606: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+----------------+-----------------+-----------------+\n",
      "| Package | Client         | Scheduler       | Workers         |\n",
      "+---------+----------------+-----------------+-----------------+\n",
      "| python  | 3.10.9.final.0 | 3.10.12.final.0 | 3.10.12.final.0 |\n",
      "+---------+----------------+-----------------+-----------------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "from coiled import Cluster\n",
    "\n",
    "from epengine.worker.main import arun\n",
    "\n",
    "worker_image_name = \"ml-for-bem-coiledworker\"\n",
    "worker_image_name = \"hatchet/epengine\"\n",
    "\n",
    "cluster = Cluster(\n",
    "    n_workers=4,\n",
    "    name=\"hatchet-worker-cluster\",\n",
    "    container=f\"{AWS_ACCOUNT_ID}.dkr.ecr.{AWS_REGION}.amazonaws.com/{worker_image_name}:latest\",\n",
    "    worker_cpu=[8],\n",
    "    worker_memory=[\"2 Gib\", \"16 Gib\"],\n",
    "    environ={\"HATCHET_CLIENT_TOKEN\": HATCHET_CLIENT_TOKEN},\n",
    "    spot_policy=\"spot\",\n",
    "    region=AWS_REGION,\n",
    "    mount_bucket=f\"s3://{AWS_BUCKET}\",\n",
    ")\n",
    "client = cluster.get_client()\n",
    "\n",
    "\n",
    "# for _ in range(100):\n",
    "#     client.submit(arun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zip() argument 2 is longer than argument 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 71\u001b[0m\n\u001b[0;32m     66\u001b[0m res \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m     67\u001b[0m     simulate,\n\u001b[0;32m     68\u001b[0m     [spec\u001b[38;5;241m.\u001b[39mmodel_dump(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m sim_specs] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     70\u001b[0m results \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mgather(res, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m erred \u001b[38;5;241m=\u001b[39m [(spec, r) \u001b[38;5;28;01mfor\u001b[39;00m spec, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sim_specs, res, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[4], line 71\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m res \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m     67\u001b[0m     simulate,\n\u001b[0;32m     68\u001b[0m     [spec\u001b[38;5;241m.\u001b[39mmodel_dump(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m spec \u001b[38;5;129;01min\u001b[39;00m sim_specs] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     70\u001b[0m results \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mgather(res, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m erred \u001b[38;5;241m=\u001b[39m [(spec, r) \u001b[38;5;28;01mfor\u001b[39;00m spec, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sim_specs, res, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: zip() argument 2 is longer than argument 1"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from epengine.models.configs import fetch_uri\n",
    "from epengine.models.ddy_injector import DDYSizingSpec\n",
    "\n",
    "logger = logging.getLogger(\"SIM-DASK-WORKER\")\n",
    "\n",
    "\n",
    "def simulate(spec: dict):\n",
    "    # logger.info(f\"Running simulation for {spec}\")\n",
    "    # print(f\"Running simulation for {spec}\")\n",
    "    sim_spec = SimulationSpec.model_validate(spec)\n",
    "    # logger.info(str(os.listdir(\"/mount\")))\n",
    "    # print(str(os.listdir(\"/mount\")))\n",
    "\n",
    "    mount_idf_path = f\"/mount/{str(sim_spec.idf_uri)[5:]}\"\n",
    "    mount_ddy_path = f\"/mount/{str(sim_spec.ddy_uri)[5:]}\" if sim_spec.ddy_uri else None\n",
    "    mount_epw_path = f\"/mount/{str(sim_spec.epw_uri)[5:]}\"\n",
    "    fetch_uri(sim_spec.idf_uri, Path(mount_idf_path))\n",
    "    fetch_uri(sim_spec.epw_uri, Path(mount_epw_path))\n",
    "    if mount_ddy_path:\n",
    "        fetch_uri(sim_spec.ddy_uri, Path(mount_ddy_path))\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        local_idf_path = Path(tmpdir) / \"model.idf\"\n",
    "        local_epw_path = Path(tmpdir) / \"model.epw\"\n",
    "        shutil.copyfile(mount_idf_path, local_idf_path)\n",
    "        shutil.copyfile(mount_epw_path, local_epw_path)\n",
    "        if mount_ddy_path:\n",
    "            local_ddy_path = Path(tmpdir) / \"model.ddy\"\n",
    "            shutil.copyfile(mount_ddy_path, local_ddy_path)\n",
    "        else:\n",
    "            local_ddy_path = None\n",
    "        idf = IDF(\n",
    "            local_idf_path.as_posix(),\n",
    "            epw=local_epw_path.as_posix(),\n",
    "            output_directory=tmpdir,\n",
    "            as_version=None,  # pyright: ignore [reportArgumentType]\n",
    "        )\n",
    "        if local_ddy_path:\n",
    "            ddy = IDF(\n",
    "                local_ddy_path.as_posix(),\n",
    "                output_directory=tmpdir,\n",
    "                as_version=\"9.5.0\",\n",
    "                file_version=\"9.5.0\",\n",
    "                prep_outputs=False,\n",
    "            )\n",
    "            ddy_spec = DDYSizingSpec(\n",
    "                design_days=[\"Ann Clg .4% Condns DB=>MWB\", \"Ann Htg 99.6% Condns DB\"],\n",
    "            )\n",
    "            ddy_spec.inject_ddy(idf, ddy)\n",
    "        idf.simulate()\n",
    "        sql = Sql(idf.sql_file)\n",
    "        dfs = postprocess(\n",
    "            sql,\n",
    "            index_data=sim_spec.model_dump(mode=\"json\", exclude_none=True),\n",
    "            tabular_lookups=[(\"AnnualBuildingUtilityPerformanceSummary\", \"End Uses\")],\n",
    "        )\n",
    "    dfs = serialize_df_dict(dfs)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "sim_args = [spec.model_dump(mode=\"json\") for spec in sim_specs] * 8\n",
    "res = client.map(\n",
    "    simulate,\n",
    "    sim_args,\n",
    ")\n",
    "results = client.gather(res, errors=\"skip\")\n",
    "erred = [(spec, r) for spec, r in zip(sim_args, res, strict=True) if r.status != \"finished\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Future: arun</strong>\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> status: </span>\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-error-color0, black)\">pending</span>,\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> type:</span> NoneType,\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> key:</span> arun-5c07f9bc86379258efced46d37cd7f69"
      ],
      "text/plain": [
       "<Future: pending, key: arun-5c07f9bc86379258efced46d37cd7f69>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.submit(arun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-22 17:50:27,612][INFO    ][coiled] Cluster 597308 deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m      4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnnualBuildingUtilityPerformanceSummary_End_Uses\u001b[39m\u001b[38;5;124m\"\u001b[39m], orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(results)\n\u001b[0;32m      6\u001b[0m ])\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m----> 4\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnnualBuildingUtilityPerformanceSummary_End_Uses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(results)\n\u001b[0;32m      6\u001b[0m ])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.concat([\n",
    "    pd.DataFrame.from_dict(result[\"AnnualBuildingUtilityPerformanceSummary_End_Uses\"], orient=\"tight\")\n",
    "    for result in list(results)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
